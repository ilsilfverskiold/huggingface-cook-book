{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvl+4/UHB/cRlXQdVB/doz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilsilfverskiold/transformers-nlp-docs/blob/main/cook/using/pipeline_testing_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "iaLjQl1tYbyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Go find a (fine-tuned) model here you want to test first: https://huggingface.co/models (or try with a few random ones below)"
      ],
      "metadata": {
        "id": "Ena5-EnXZ3t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH8oAPuNX3Iv"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "# pipeline is a high-level helper (you can also load model directly)\n",
        "\n",
        "# Sentiment analysis with a distilBERT (encoder model)\n",
        "pipe = pipeline('sentiment-analysis', model='lxyuan/distilbert-base-multilingual-cased-sentiments-student')\n",
        "print(pipe(\"I like you. I love you\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text generation task with T5 (seq-to-seq model)\n",
        "pipe = pipeline('text2text-generation', model='EnglishVoice/t5-base-keywords-to-headline')\n",
        "print(pipe(\"headline: developer productivity\"))"
      ],
      "metadata": {
        "id": "FcP9j4CRZ14p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization task with BART (seq-to-seq model)\n",
        "pipe = pipeline(\"summarization\", model=\"slauw87/bart_summarisation\")\n",
        "print(pipe(\"Sugi: I am tired of everything in my life. Tommy: What? How happy you life is! I do envy you. Sugi: You don't know that I have been over-protected by my mother these years. I am really about to leave the family and spread my wings. Tommy: Maybe you are right. \"))"
      ],
      "metadata": {
        "id": "lG_HCbRoa9Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text classification with a BERT model (encoder model)\n",
        "pipe = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
        "print(pipe(\"I like you. I love you\"))"
      ],
      "metadata": {
        "id": "20jPUSO2cHHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text classification with a Roberta model (encoder model)\n",
        "\n",
        "# Delicate text detection task (see model card here: https://huggingface.co/grammarly/detexd-roberta-base)\n",
        "pipe = pipeline(\"text-classification\", model=\"grammarly/detexd-roberta-base\")\n",
        "print(pipe(\"Shares in Twitter closed 6.35% up after an SEC 13D filing revealed that Elon Musk pledged to put up an additional $6.25 billion of his own wealth to fund the $44 billion takeover deal, lifting the total to $33.5 billion from an initial $27.25 billion. In other news: Former Twitter CEO Jack Dorsey announced he's stepping down, but would stay on Twitterâ€™s board.\"))"
      ],
      "metadata": {
        "id": "r6S6W1L6cuBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll try my model too! (Keyword extraction with a BART a seq-to-seq model)\n",
        "\n",
        "pipe = pipeline('summarization', model='ilsilfverskiold/tech-keywords-extractor')\n",
        "print(pipe(\"I'm reaching out for some guidance on choosing the right no-code or low-code platform for my web app development projects. As a proficient back-end developer with a strong grasp of AWS, I have always struggled with front-end development\"))"
      ],
      "metadata": {
        "id": "gYtsP0uJZPko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}