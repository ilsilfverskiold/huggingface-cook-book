{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilsilfverskiold/smaller-models-docs/blob/main/computer-vision/cook/image-classification/Image_classification_resnet_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image classification with a CNN using Hugging Face**\n",
        "\n",
        "---\n",
        "\n",
        "The pre-trained model we'll fine-tune here is set at for microsoft/resnet-50, possibly works for other similar models.\n",
        "\n",
        "Batch size is 32, epoch is 3.\n",
        "\n",
        "**Make sure you change the dataset to what you need.** My dataset I've used has both a training and a validation set, so change the code accordingly if you don't have a validation set."
      ],
      "metadata": {
        "id": "7ovib44E13ub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu8LgohRoC65"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"ilsilfverskiold/traffic-camera-norway-images\" # public dataset\n",
        "model_checkpoint = \"microsoft/resnet-50\" # decide on your pre-trained model\n",
        "learning_rate = 5e-5\n",
        "weight_decay = 0.01\n",
        "epochs = 3\n",
        "batch_size= 32"
      ],
      "metadata": {
        "id": "DtUgPqQR2NlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the dataset from huggingface below."
      ],
      "metadata": {
        "id": "OMtxurcY28LW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oySzD-7UoGq6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(dataset_url) # possible to import private too by setting token=your_token\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the features and get the labels. Make sure the images are in PIL format."
      ],
      "metadata": {
        "id": "ApL3n2xR2-hx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnjkbssrocrB"
      },
      "outputs": [],
      "source": [
        "dataset[\"train\"].features[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIk6Bo_tomZY"
      },
      "outputs": [],
      "source": [
        "labels = dataset[\"train\"].features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll have to preprocess the data below using data normalization, augmentation, and compatibility with model input requirements. These preprocessing steps are critical for adapting the input data to the format expected by the ResNet-50 model, aligning the new training or validation data closely with the conditions of the original training set."
      ],
      "metadata": {
        "id": "U7X6Rnc23tLk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvL6c00fpCKe"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, Normalize, Resize, CenterCrop, RandomHorizontalFlip, ToTensor\n",
        "from transformers import AutoFeatureExtractor\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)\n",
        "\n",
        "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "\n",
        "train_transform = Compose([\n",
        "    Resize(256),\n",
        "    CenterCrop(224),\n",
        "    RandomHorizontalFlip(),\n",
        "    ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "val_transform = Compose([\n",
        "    Resize(256),\n",
        "    CenterCrop(224),\n",
        "    ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "def apply_transform(examples, transform):\n",
        "    \"\"\"Applies the transform to the 'img' key in examples.\"\"\"\n",
        "    examples['pixel_values'] = [transform(image.convert('RGB')) for image in examples['image']]\n",
        "    return examples\n",
        "\n",
        "def set_dataset_transform(dataset, transform):\n",
        "    dataset.set_transform(lambda examples: apply_transform(examples, transform))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G5Nn6d2pOdu"
      },
      "outputs": [],
      "source": [
        "set_dataset_transform(dataset['train'], train_transform)\n",
        "set_dataset_transform(dataset['validation'], val_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that you have a new field called pixel_values with tensors for the first item in the training data."
      ],
      "metadata": {
        "id": "BHuecU8J4Kzo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlBCnPuMpVB-"
      },
      "outputs": [],
      "source": [
        "dataset['train'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the labels we set up earlier from the dataset when importing the pre-trained model below, we also tell it to ignore the pre-defined labels that it previously have been trained on."
      ],
      "metadata": {
        "id": "O26Wq6DS4kj4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCcZrRm7phOc"
      },
      "outputs": [],
      "source": [
        "from transformers import TFAutoModelForImageClassification\n",
        "\n",
        "model = TFAutoModelForImageClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up the compute metrics, your choice to have less."
      ],
      "metadata": {
        "id": "CPAal3bC4tcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "precision_metric = load_metric(\"precision\")\n",
        "recall_metric = load_metric(\"recall\")\n",
        "f1_metric = load_metric(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    precision = precision_metric.compute(predictions=predictions, references=labels, average='macro')\n",
        "    recall = recall_metric.compute(predictions=predictions, references=labels, average='macro')\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy['accuracy'],\n",
        "        \"precision\": precision['precision'],\n",
        "        \"recall\": recall['recall'],\n",
        "        \"f1\": f1['f1']\n",
        "    }\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "lId-0bE7ZZ_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll set an optimizer as well. An optimizer is a method or algorithm for adjusting the parameters of neural networks based on the feedback from the loss function."
      ],
      "metadata": {
        "id": "Dxk9WTqE5ZZn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azK0yL57plzr"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamWeightDecay\n",
        "\n",
        "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKhmOpbCpolB"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A data collator, like the DefaultDataCollator, ensures that batches of data are appropriately processed and standardized, handling tasks like padding and converting data to the required format, crucial for training machine learning models efficiently."
      ],
      "metadata": {
        "id": "ufgc-5sR6GO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G47dyWupps5E"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator(return_tensors=\"np\")\n",
        "\n",
        "train_set = dataset['train'].to_tf_dataset(\n",
        "    columns=[\"pixel_values\", \"label\"],\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "val_set = dataset['validation'].to_tf_dataset(\n",
        "    columns=[\"pixel_values\", \"label\"],\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyXviQhmp16T"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model below using the transformers library, make sure you check training loss and accuracy. Training loss should consistently go down while accuracy should go up."
      ],
      "metadata": {
        "id": "D12YDuhy6SvH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV9dzgXvqiAV"
      },
      "outputs": [],
      "source": [
        "from transformers.keras_callbacks import PushToHubCallback, KerasMetricCallback\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "metric_callback = KerasMetricCallback(\n",
        "    metric_fn=compute_metrics, eval_dataset=val_set, batch_size=batch_size, label_cols=['labels']\n",
        ")\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir=\"./ic_from_scratch_model_save/logs\")\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "callbacks = [metric_callback, tensorboard_callback]\n",
        "\n",
        "model.fit(\n",
        "    train_set,\n",
        "    validation_data=val_set,\n",
        "    callbacks=callbacks,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate on the validation set"
      ],
      "metadata": {
        "id": "FShSCQz66fg0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uYEp70YrZYw"
      },
      "outputs": [],
      "source": [
        "eval_loss = model.evaluate(val_set)\n",
        "eval_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9KKiPDGrcaP"
      },
      "outputs": [],
      "source": [
        "for batch in iter(val_set):\n",
        "    predictions = model.predict(batch)\n",
        "    predicted_labels = np.argmax(predictions.logits, -1)\n",
        "    metric.add_batch(predictions=predicted_labels, references=batch['labels'])\n",
        "\n",
        "metric.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP9AElERrhsR"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"my_model\", saved_model=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HyByDhqrrx2"
      },
      "outputs": [],
      "source": [
        "from transformers import TFAutoModelForImageClassification\n",
        "\n",
        "model = TFAutoModelForImageClassification.from_pretrained(\"my_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGmPNx10rvUp"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"image-classification\", model=model, feature_extractor=feature_extractor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(optional) use a few new images in your Google Drive to to inference on to see how it performs."
      ],
      "metadata": {
        "id": "EZU7cgMD6qcC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVpSFCqTry6m"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9uSSnvvr0dD"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_path = '/content/drive/MyDrive/my_new_image.png' # change this to the correct path\n",
        "\n",
        "image = Image.open(image_path)\n",
        "image\n",
        "\n",
        "results = pipe(image)\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyO683R64nVuuu5ES/fl+7gF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
